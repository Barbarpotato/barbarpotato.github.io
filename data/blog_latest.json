[
  {
    "blog_id": "52eb37c3-83bc-4442-a8c5-305bfba74e62",
    "title": "Why API Versioning is Really Important: A Lesson from My Own Mistake",
    "short_description": "As a developer, I've built countless APIs for my personal projects. Some were experimental, some turned into full-fledged applications, and others were simply abandoned over time. At first, managing these APIs felt simple—if I wasn't using an endpoint anymore, I would just delete it. Why keep something that I no longer need, right?  Well, that mindset came back to bite me.",
    "timestamp": "2025-02-16 13:35:40",
    "description": "<h1><strong>The Mistake That Taught Me a Lesson</strong></h1><p>One day, I was cleaning up an old project, removing unused routes and refactoring the backend. There was this one API endpoint—let's call it /user/details—that I thought was no longer in use. Without a second thought, I deleted it and pushed the changes to production.</p><p>A few hours later, I started receiving errors from another service I had built months earlier. This service, which I had completely forgotten about, was still making requests to /user/details. Suddenly, parts of my application were broken, and I had no easy way to recover from it.</p><p>That was the moment I truly understood why API versioning is critical.</p><h2><strong>Why API Versioning Matters</strong></h2><p><strong>1. Prevents Breaking Changes</strong></p><p>When APIs evolve, clients relying on them should not break due to changes. By implementing versioning (e.g., /v1/user/details), I could have introduced a new version while keeping the old one intact for existing consumers.</p><p><strong>2. Maintains Backward Compatibility</strong></p><p>Even if you think an API is no longer needed, there’s a chance some service or third-party client is still using it. Versioning allows developers to deprecate old APIs gradually rather than abruptly removing them.</p><p><strong>3. Gives Users Time to Migrate</strong></p><p>If an API must change, users need time to update their applications. Providing multiple versions (e.g., /v1/, /v2/) ensures a smooth transition.</p><p><strong>4. Helps in Debugging and Maintenance</strong></p><p>When multiple versions exist, issues can be traced more easily. If a bug appears in /v2/ but not in /v1/, it’s easier to identify what changes might have caused it.</p><h2>How to Implement API Versioning</h2><h3>1. <strong>URL Versioning</strong></h3><p>The most common and widely adopted approach to API versioning is using version numbers in the URL.</p><div><pre><code>/v1/users\n/v2/users\n</code></pre></div><h4>Pros:</h4><ul><li><strong>Easy to understand and implement</strong> – Developers can quickly identify which version is being used.</li><li><strong>Clear distinction between versions</strong> – Each version has its own endpoint, ensuring that changes do not interfere with older versions.</li></ul><h4>Cons:</h4><ul><li><strong>Can lead to bloated URLs</strong> – If too many versions exist, the API can become cluttered.</li><li><strong>Might require modifying routes and maintaining multiple endpoints</strong> – Developers must maintain multiple versions, which can increase complexity over time.</li></ul><h3>2. <strong>Header Versioning</strong></h3><p>Another approach is to use HTTP headers to specify the API version instead of embedding it in the URL.</p><div><pre><code>Accept: application/vnd.myapi.v1+json\n</code></pre></div><h4>Pros:</h4><ul><li><strong>Keeps URLs clean</strong> – There’s no need to modify the URL structure, making it aesthetically cleaner.</li><li><strong>Allows more flexibility without changing routes</strong> – Clients can request different versions dynamically using headers.</li></ul><h4>Cons:</h4><ul><li><strong>Requires clients to send custom headers explicitly</strong> – Clients must be aware of the correct headers to use, which adds complexity.</li><li><strong>Might be harder to test and debug compared to URL versioning</strong> – Since versioning is not visible in the URL, debugging and API documentation can be more challenging.</li></ul><h3>3. <strong>Query Parameter Versioning</strong></h3><p>This method involves specifying the API version as a query parameter in the request.</p><div><pre><code>/users?version=1\n</code></pre></div><h4>Pros:</h4><ul><li><strong>Simple to implement and does not require changes to routes</strong> – The backend can handle different versions without modifying the API structure.</li><li><strong>Can be easily handled on the backend</strong> – Developers can dynamically parse the version parameter and route requests accordingly.</li></ul><h4>Cons:</h4><ul><li><strong>Can lead to inconsistent API calls if clients forget to include the version</strong> – If a request is made without the version parameter, it may result in unintended behavior.</li><li><strong>May clutter the query string with additional parameters</strong> – This approach can become cumbersome if multiple parameters are needed.</li></ul><h2><strong>Choosing the Right API Versioning Strategy</strong></h2><p>Each of these methods has its strengths and weaknesses, and the best approach depends on the specific needs of your project. If you want a simple and widely understood method, <strong>URL versioning</strong> might be the best choice. If you prefer a cleaner URL structure, <strong>header versioning</strong> could be a better fit. And if you need quick implementation without altering routes, <strong>query parameter versioning</strong> is a viable option.</p><h2><strong>Final Thoughts</strong></h2><p>I learned the hard way that careless API deletions can lead to unexpected failures. If I had implemented proper versioning, I could have safely iterated on my APIs without breaking my own services.</p><p>So, if you're developing APIs—whether for personal projects or production systems—take API versioning seriously. Your future self (and your users) will thank you!</p>",
    "image": "https://storage.googleapis.com/personal-blog-darmajr.appspot.com/blog-content/1739712690763_api-versioning-strategy.jpg",
    "image_alt": "Api Versioning",
    "slug": "Why-API-Versioning-is-Really-Important-A-Lesson-from-My-Own-Mistake"
  },
  {
    "blog_id": "911a9001-3c3e-4f2c-aa83-4ec4f6f71c99",
    "title": "Terraform Labs: Automating Google Cloud Infrastructure Deployment",
    "short_description": "Manually managing cloud infrastructure can be time-consuming and error-prone. Terraform changes the game by allowing you to define infrastructure as code, making deployment faster, scalable, and repeatable. With Terraform, you can automate cloud resource creation, track changes, and collaborate effortlessly.",
    "timestamp": "2025-02-16 02:15:22",
    "description": "<h2><strong>How Does Terraform Work?</strong></h2><h3><strong>1. Declarative Configuration</strong></h3><p>Terraform uses a special language called <strong>HashiCorp Configuration Language (HCL)</strong>. Instead of writing step-by-step instructions like in traditional programming, you just <strong>describe what you want</strong> (e.g., \"I need a virtual machine with 2 CPUs and 4GB RAM\"), and Terraform figures out how to make it happen.</p><h3><strong>2. Configuration Interpretation</strong></h3><p>When you run a Terraform command, it reads your configuration files and <strong>understands what infrastructure you want to create or update</strong>.</p><h3><strong>3. Interaction with Cloud APIs</strong></h3><p>Terraform then communicates with cloud providers like <strong>Google Cloud, AWS, or Azure</strong> by sending <strong>API requests</strong>. This tells the cloud provider to create, update, or delete the resources you defined.</p><h3><strong>4. Execution by Cloud Providers</strong></h3><p>The cloud provider takes Terraform’s instructions and <strong>builds your infrastructure</strong>—creating things like virtual machines, networks, and storage based on your configuration.</p><h3><strong>5. State Management</strong></h3><p>Terraform keeps track of everything it has created in a <strong>state file</strong>. This file helps Terraform know what’s already there, so it only makes <strong>necessary changes</strong> when you update your configuration.</p><h3><strong>Why Use Terraform?</strong></h3><p>Terraform makes infrastructure management <strong>simpler, repeatable, and error-free</strong>. Instead of manually clicking around in cloud dashboards, you can <strong>automate everything</strong> with a few lines of code. This saves time and reduces mistakes.</p><p>Terraform enables you to safely and predictably create, change, and improve infrastructure. It is an open-source tool that codifies APIs into declarative configuration files that can be shared among team members, treated as code, edited, reviewed, and versioned.</p><p>In this lab, you create a Terraform configuration with a module to automate the deployment of Google Cloud infrastructure.</p><h2><strong>Task 1: Setting Up Terraform and Cloud Shell</strong></h2><h3><strong>Installing Terraform</strong></h3><p>Terraform is pre-installed in Cloud Shell. Verify the installed version.</p><p>1 Open <strong>Google Cloud Console</strong> and click <strong>Activate Cloud Shell</strong>.</p><p>2 If prompted, click <strong>Continue</strong>.</p><p>3 Run the following command to check the Terraform version:</p><div><pre><code>terraform --version\n</code></pre></div><p><strong>- Expected output:</strong></p><div><pre><code>Terraform v1.3.3\n</code></pre></div><blockquote><strong>Note:</strong> These lab instructions work with Terraform v1.3.3 and later.</blockquote><p>4 Create a directory for Terraform configurations:</p><div><pre><code>mkdir tfinfra\n</code></pre></div><p>5 Open <strong>Cloud Shell Editor</strong> and navigate to the <strong><em>tfinfra </em></strong>folder.</p><h3><strong>Initializing Terraform</strong></h3><p>Terraform uses plugins to support various cloud providers. Initialize Terraform by setting Google as the provider.</p><p>1 Create a new file named <strong>provider.tf</strong> tfinfra folder.</p><p>2 Add the following configuration:</p><div><pre><code>provider \"google\" {}\n</code></pre></div><p>3 Save the file.</p><p>4 Run the Terraform initialization command:</p><div><pre><code>cd tfinfra\nterraform init\n</code></pre></div><p><strong>- Expected output:</strong></p><div><pre><code>provider.google: version = \"~&gt; 4.43.0\"\nTerraform has been successfully initialized!\n</code></pre></div><h2><strong>Task 2: Creating mynetwork and Its Resources</strong></h2><h3><strong>Configuring mynetwork</strong></h3><p>1 Create a new file named <strong>mynetwork.tf</strong> inside tfinfra.</p><p>2 Add the following configuration:</p><div><pre><code>resource \"google_compute_network\" \"mynetwork\" {\n  name                    = \"mynetwork\"\n  auto_create_subnetworks = true\n}\n</code></pre></div><p>3 Save the file.</p><h3><strong>Configuring Firewall Rules</strong></h3><p>4 Add the following firewall rules to mynetwork,tf:</p><div><pre><code>resource \"google_compute_firewall\" \"mynetwork-allow-http-ssh-rdp-icmp\" {\n  name    = \"mynetwork-allow-http-ssh-rdp-icmp\"\n  network = google_compute_network.mynetwork.self_link\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"22\", \"80\", \"3389\"]\n  }\n  allow {\n    protocol = \"icmp\"\n  }\n  source_ranges = [\"0.0.0.0/0\"]\n}\n</code></pre></div><p>5 Save the file.</p><h3><strong>Configuring VM Instance</strong></h3><p>1 Create a new folder named <strong>instance</strong> inside tfinfra.</p><p>2 Create a new file <strong>main.tf</strong> inside the instance folder.</p><p>3 Add the following basic configuration:</p><div><pre><code>resource \"google_compute_instance\" \"vm_instance\" {\n  name         = \"my-vm-instance\"\n  machine_type = \"e2-medium\"\n  zone         = \"us-central1-a\"\n\n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-10\"\n    }\n  }\n  network_interface {\n    network = google_compute_network.mynetwork.self_link\n  }\n}\n</code></pre></div><p>4 Save the file.</p><p>To rewrite the Terraform configuration files to a canonical format and style, run the following command:</p><div><pre><code>terraform fmt\n</code></pre></div><p>To initialize Terraform, run the following command:</p><div><pre><code>terraform init\n</code></pre></div><p><strong>Expected output:</strong></p><div><pre><code>...\n* provider.google: version = \"~&gt; 4.43.0\"\n\nTerraform has been successfully initialized!\n</code></pre></div><h2><strong>Conclusion</strong></h2><p>You have successfully set up Terraform in Cloud Shell and created configurations to deploy Google Cloud infrastructure, including a VPC network, firewall rules, and VM instances. Terraform’s execution workflow ensures smooth infrastructure deployment with minimal manual intervention. This setup can be expanded with additional configurations and modules to efficiently automate more complex infrastructure deployments.</p><p>Happy learning and coding with Terraform!</p>",
    "image": "https://storage.googleapis.com/personal-blog-darmajr.appspot.com/blog-content/1739669992396_gcp-terraform.png",
    "image_alt": "Terraform with GCP",
    "slug": "Terraform-Labs-Automating-Google-Cloud-Infrastructure-Deployment"
  },
  {
    "blog_id": "109a123a-02ae-4b9f-96a9-785428eef2fa",
    "title": "Jenkins Unleashed: Transforming Your CI/CD Workflow for Lightning-Fast Delivery",
    "short_description": "In the fast-paced world of modern software development, delivering high-quality applications quickly is no longer optional—it's essential. This is where Jenkins steps in as a game-changer. Imagine having a virtual assistant that tirelessly builds, tests, and deploys your code, ensuring every update you make reaches production seamlessly.",
    "timestamp": "2025-01-06 12:32:13",
    "description": "<h1><strong>Why Use Jenkins for CI/CD?</strong></h1><p>Jenkins is not just a tool; it's a culture shifter. With its unparalleled flexibility, thousands of plugins, and vibrant community, Jenkins transforms how teams approach Continuous Integration and Continuous Delivery (CI/CD). Whether you’re a small startup racing to push your MVP or a large enterprise managing complex workflows, Jenkins empowers you to automate repetitive tasks, reduce errors, and accelerate delivery pipelines.</p><p>But why Jenkins? It’s open-source, highly customizable, and scales effortlessly with your team’s growing needs. It’s the bridge between developers and operations teams, breaking down silos and fostering collaboration in ways you’ve never experienced before.</p><p>In this labs, we’ll explore the magic of Jenkins and why it’s the go-to choice for CI/CD pipelines. Ready to revolutionize your development workflow? Let’s dive in!</p><h1><strong>Setting Up CI/CD in Jenkins</strong></h1><p>To start setting up CI/CD with Jenkins, the first step is to prepare your environment by installing Java. Jenkins requires Java to run, so you need to install OpenJDK 17. Update your system packages and install Java by running the following commands:</p><div><pre><code>sudo apt update\nsudo apt install fontconfig openjdk-17-jre\njava -version\n</code></pre></div><p>After installation, you can verify the version of Java to ensure everything is properly set up. The output should display the installed version, such as openJDK version 17. With Java in place, your system is now ready to host Jenkins.</p><p>Next, install Jenkins using its official package repository to ensure you're getting the latest stable release. First, add Jenkins' repository key and configuration to your system, update the package list, and install Jenkins by running these commands:</p><div><pre><code>sudo wget -O /usr/share/keyrings/jenkins-keyring.asc \\\n  https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key\necho \"deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc]\" \\\n  https://pkg.jenkins.io/debian-stable binary/ | sudo tee \\\n  /etc/apt/sources.list.d/jenkins.list &gt; /dev/null\nsudo apt-get update\nsudo apt-get install jenkins\n</code></pre></div><p>Once Jenkins is installed, you need to enable and start the Jenkins service. This ensures Jenkins runs immediately and starts automatically whenever the system boots. Use the following commands to enable and start Jenkins:</p><div><pre><code>sudo systemctl enable jenkins\nsudo systemctl start jenkins\nsudo systemctl status jenkins\n</code></pre></div><p>After starting the service, you can access Jenkins through your browser. Open http://[VM_EXTERNAL_IP]:8080&nbsp;and log in using the initial admin password. To retrieve this password, run:</p><div><pre><code>sudo cat /var/lib/jenkins/secrets/initialAdminPassword\n</code></pre></div><p>Enter the password on the setup screen and follow the guided setup wizard. This process will include installing recommended plugins, such as Git, Pipeline, Blue Ocean, and GitHub, which are essential for building your CI/CD pipeline.</p><p>In addition to plugins, configure credentials for accessing your source code repository. Navigate to <strong>Manage Jenkins &gt; Credentials</strong>, and add secure credentials for platforms like GitHub or GitLab. This setup ensures your pipeline can pull code from your repositories securely.</p><p>With Jenkins configured, you’re ready to create your first pipeline. The pipeline script can define all stages of your CI/CD process, such as fetching code, running tests, and deploying to production.</p><h1><strong>Setting Up Git Credentials for Private Repositories</strong></h1><p>If your project is hosted on a private Git platform, you’ll need to provide secure credentials for Jenkins to access the repository. For GitHub users, this involves creating a Personal Access Token (PAT) and adding it to Jenkins' credentials. This ensures seamless integration between Jenkins and your repository without compromising security.</p><h2><strong>Creating a Personal Access Token (PAT) on GitHub</strong></h2><p>To create a PAT in GitHub:</p><p>1. Go to your GitHub account settings.</p><p>2. Navigate to Developer settings &gt; Personal Access Tokens &gt; Tokens (classic).</p><p>3. Click Generate new token and specify the required permissions. For most CI/CD setups, select scopes like repo (for repository access) and workflow (if managing GitHub Actions).</p><p>4. Generate the token and copy it. Make sure to store it securely as you won’t be able to view it again.</p><h2>Configuring Jenkins with GitHub Credentials</h2><p>Once you’ve created your PAT, follow these steps to add it to Jenkins:</p><p>1. Log in to the Jenkins Dashboard.</p><p>2. Navigate to Manage Jenkins &gt; Manage Credentials.</p><p>3. Under (global) credentials, click Add Credentials.</p><p>4. In the Kind dropdown, select Username with password.</p><p>Username: Enter your GitHub username (e.g., username).</p><p>Password: Paste the PAT you just created.</p><p>5. Give the credential a recognizable ID (e.g., github-creds) and click OK.</p><h1>Writing Your First Jenkins Pipeline</h1><p>With Jenkins configured, you’re ready to create your first pipeline. The pipeline script defines all stages of your CI/CD process, including fetching code, running tests, and deploying the application. Let’s walk through an example pipeline written using Jenkins' declarative syntax, which simplifies the process and ensures better readability.</p><h4>Understanding the Pipeline Script</h4><p>Below is an example pipeline that automates three key stages of the CI/CD process:</p><p><strong>1. Fetching the code from GitHub</strong> using credentials for a secure connection.</p><p><strong>2. Running basic testing commands</strong> to verify the environment setup.</p><p><strong>3. Deploying the application</strong> to a server using SSH for remote commands</p><div><pre><code>pipeline {\n&nbsp; &nbsp; agent any\n&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; environment {\n&nbsp; &nbsp; &nbsp; &nbsp; GITHUB_CREDENTIALS = 'caea020d-a24e-4305-bdc2-d7e51d1c8171'&nbsp; // ID of the GitHub credentials in Jenkins\n&nbsp; &nbsp; }\n&nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; stages {\n&nbsp; &nbsp; &nbsp; &nbsp; stage('Git Checkout') {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; steps {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; script {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // Cloning the GitHub repository using the provided credentials\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; git credentialsId: \"${GITHUB_CREDENTIALS}\", url: 'https://github.com/Barbarpotato/API-Registry.git', branch: 'main'\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; stage('Run Testing Commands') {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; steps {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sh 'hostname'&nbsp; // Outputs the hostname of the Jenkins agent\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sh 'pwd'&nbsp; &nbsp; &nbsp; &nbsp;// Displays the current working directory in the agent's workspace\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;\n&nbsp; &nbsp; &nbsp; &nbsp; stage('Deploy to Server') {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; steps {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // Using SSH to deploy the application to the target server\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sshagent(['ssh-key-gateway']) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sh '''\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ssh -o StrictHostKeyChecking=no darmawanjr88@34.101.205.217 &lt;&lt; EOF\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cd API-Registry\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; git pull origin main\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; pm2 restart all\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; exit\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; EOF\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; '''\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; }\n}\n</code></pre></div><p>The provided pipeline script is a clear example of how Jenkins orchestrates the CI/CD process, broken into multiple stages for ease of management. Let's break it down section by section and explain how each part works in a simplified, interactive way.</p><h3>Pipeline Declaration</h3><p>At the heart of any Jenkins pipeline is the pipeline block, which defines the entire process. Inside this block, the agent any directive tells Jenkins to run the pipeline on any available agent, whether it's a master or a worker node. This flexibility is useful when you have multiple agents configured and don’t want to restrict the execution to a specific one.</p><h3>Environment Variables</h3><p>Next, we have the environment block. This is where we can define variables that are reused across the pipeline. In this case, the variable GITHUB_CREDENTIALS holds the ID of the GitHub credentials that Jenkins uses to securely access the private repository. By defining it here, you ensure it’s easily reusable without hardcoding it into every step. Think of it as a centralized way to manage sensitive data like tokens and credentials, making the pipeline both secure and maintainable.</p><h3>Stages</h3><p>The pipeline is broken into logical steps called \"stages,\" each representing a part of the CI/CD workflow.</p><p>1. Git Checkout</p><p>In the first stage, Jenkins clones the GitHub repository using the git step. The credentialsId points to the pre-configured GitHub credentials stored in Jenkins. This ensures secure and seamless access to the private repository without exposing sensitive information. This step lays the foundation for the entire pipeline, as it fetches the code that the remaining stages will process.</p><p>2. Run Testing Commands</p><p>This stage is simple but powerful. It runs shell commands such as hostname and pwd, which output the hostname of the Jenkins agent and the current working directory, respectively. While these commands are placeholders here, you can replace them with actual test scripts. For instance, if you’re running unit tests, you could include a command like npm test or pytest. The purpose of this stage is to ensure the environment is configured correctly and ready for further operations.</p><p>3. Deploy to Server</p><p>This stage demonstrates how Jenkins can deploy your application to a production or staging server. Using the sshagent block, Jenkins securely connects to the target server via SSH. It then pulls the latest changes from the repository and restarts the application using PM2, a popular process manager for Node.js. This setup ensures that the application is always up-to-date with the latest code changes, and the restart command ensures a smooth rollout of updates.</p><p>Continuing from the previous explanation of setting up a Jenkins pipeline, the next step to truly automate the CI/CD process is to set up a <strong>push trigger</strong> using webhooks. This ensures that every time you push changes to your GitHub repository, Jenkins automatically triggers the pipeline, saving you from the hassle of manually starting the build.</p><p>Let’s explore how to set up a webhook-based trigger between GitHub and Jenkins in an intuitive and straightforward way.</p><h3><strong>What Are Webhooks?</strong></h3><p>Think of webhooks as a way for GitHub to \"talk\" to Jenkins. Whenever you push code to your repository, GitHub sends a signal (HTTP POST request) to Jenkins, telling it to start the pipeline. This creates an automated, real-time link between your code changes and the build process.</p><h3><strong>Setting Up Push Trigger (Webhook)</strong></h3><h4><strong>First, Enable GitHub Integration in Jenkins</strong></h4><p>Before setting up the webhook, you need to make sure Jenkins can communicate with GitHub. To do this, open Jenkins and go to <strong>Manage Jenkins</strong> &gt; <strong>Manage Plugins</strong>. From there, search for <strong>GitHub</strong> plugins and install them. This will allow Jenkins to recognize GitHub as a source and receive notifications from it.</p><h4><strong>Configure Jenkins to Listen for Webhooks</strong></h4><p>Next, open the Jenkins pipeline job you want to configure. In the job settings, go to <strong>Build Triggers</strong> and enable the option <strong>GitHub hook trigger for GITScm polling</strong>. This step is important because it tells Jenkins to \"listen\" for any push events from GitHub, ready to trigger the pipeline whenever changes are detected.</p><h4><strong>Set Up a Webhook in GitHub</strong></h4><p>Now, head over to your GitHub repository. Inside the <strong>Settings</strong> tab, navigate to <strong>Webhooks</strong> and click on <strong>Add webhook</strong>. You'll need to provide Jenkins with a specific endpoint where it can receive notifications from GitHub. The URL format is as follows:</p><div><pre><code>http://&lt;JENKINS_URL&gt;/github-webhook/\n</code></pre></div><p>Replace <strong><em>JENKINS_URL </em></strong>with your Jenkins server’s address. Choose <strong>application/json</strong> as the content type, and make sure the <strong>Push events</strong> option is selected. This ensures that the webhook triggers every time you push changes.</p><h4><strong>Verify the Webhook</strong></h4><p>Once everything is set up, push a commit to your GitHub repository. Then, return to Jenkins and check if the pipeline starts running automatically. If the job kicks off, the webhook is working properly.</p><h3><strong>How It All Comes Together</strong></h3><p>When you push changes to your repository, GitHub sends a webhook to Jenkins. Jenkins then triggers the pipeline to fetch the latest code, run tests, and deploy to your server. This creates a seamless CI/CD process, where every change is automatically tested and deployed.</p><h1><strong>Conclusion</strong></h1><p>In this Labs, we’ve taken a deep dive into how Jenkins can supercharge your CI/CD workflows, making it an essential tool for automating your development lifecycle. We started by setting up Jenkins, installing necessary dependencies like Java, and getting the Jenkins service up and running.</p><p>From there, we explored how to configure Jenkins to work with your GitHub repository, including managing credentials securely. With Jenkins set up and connected to GitHub, we moved on to creating a simple declarative pipeline, allowing Jenkins to automatically fetch the latest code, run tests, and deploy to your server.</p><p>We then enhanced the process by explaining how to set up push triggers using GitHub webhooks. With webhooks in place, Jenkins is able to automatically start the pipeline whenever new code is pushed to the repository, eliminating the need for manual intervention and ensuring continuous integration.</p><p>Through these steps, we’ve created a fully automated CI/CD pipeline that reacts to changes in your code, testing it and deploying it seamlessly. This not only saves time but also minimizes errors, providing faster and more reliable software delivery.</p><p>By mastering Jenkins, you’re empowering yourself to automate complex workflows, improve collaboration, and focus on building great software without worrying about the manual process of integration and deployment.</p>",
    "image": "https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fjenkins_background.png?alt=media&token=8d8f21c7-f6bd-4157-8343-12090e88d13a",
    "image_alt": "Jenkins Intro image",
    "slug": "Jenkins-Unleashed-Transforming-Your-CICD-Workflow-for-Lightning-Fast-Delivery"
  },
  {
    "blog_id": "f24fa0d0-6b50-494c-ab4d-49d1b302359f",
    "title": "Building a Robust Microservices Architecture: From gRPC to Kubernetes",
    "short_description": "In the ever-evolving world of software architecture, building a robust and scalable system is key to meeting the demands of modern applications. Recently, I had the opportunity to explore a powerful combination of technologies, starting with gRPC, translating it into HTTP/1.1, and finally deploying the system to a Kubernetes cluster. In this blog, I will take you through the journey, share the challenges I encountered, and explain why each of these steps is important for modern software systems.",
    "timestamp": "2024-12-26 07:34:04",
    "description": "<h2><strong>Why gRPC? Understanding Its Power in Microservices Communication</strong></h2><p>As we move toward building distributed systems, one of the key challenges is communication between services. In a typical microservices setup, services need to talk to each other to exchange data and process requests. The two most common approaches for communication are <strong>RESTful APIs</strong> and <strong>gRPC</strong>.</p><p>So, why did I choose <strong>gRPC</strong> for this project?</p><h2><strong>What Is gRPC?</strong></h2><p>gRPC (Google Remote Procedure Call) is a high-performance, language-agnostic framework for communication between services. Unlike REST, which relies on text-based protocols (typically JSON over HTTP/1.1), gRPC uses <strong>Protocol Buffers (protobuf)</strong> for serialization. This binary protocol is compact, efficient, and designed for high-performance communication, making it ideal for microservices that require fast and reliable data exchange.</p><h2><strong>Why Use gRPC for Microservices?</strong></h2><ul><li><strong>Faster Communication</strong>: gRPC’s binary protocol is more efficient than text-based protocols, reducing the overhead of parsing and serialization.</li><li><strong>Cross-Language Support</strong>: With gRPC, you can define your service in a language-neutral way and implement it in any language that supports gRPC (like Go, Java, Python, and more).</li><li><strong>Bidirectional Streaming</strong>: gRPC supports streaming, which makes it a great choice for real-time communication between services.</li></ul><p>However, as much as gRPC is great for communication between services, it’s not as widely supported by clients as HTTP/1.1, especially for web applications. This brings us to the next step in the process: <strong>translating gRPC to HTTP/1.1</strong> for broader client support.</p><h3><strong>Translating gRPC to HTTP/1.1 for Client Communication</strong></h3><p>While gRPC is fantastic for internal microservice communication, not all clients can directly communicate with gRPC servers. HTTP/1.1 is still the standard protocol for the majority of web browsers and external client requests. Therefore, I needed to expose the gRPC services through an <strong>API Gateway</strong>, which would translate incoming HTTP/1.1 requests into gRPC calls.</p><h4><strong>Why an API Gateway?</strong></h4><p>An <strong>API Gateway</strong> acts as a reverse proxy that forwards client requests to the appropriate service, handling routing, load balancing, and security concerns. In my case, it also handled translating HTTP requests into gRPC communication.</p><ul><li><strong>HTTP to gRPC Translation</strong>: The API Gateway receives HTTP requests from clients, translates them into gRPC requests, and then forwards them to the respective service. This allows you to expose gRPC services to HTTP clients without changing the core functionality of your services.</li><li><strong>Centralized Control</strong>: The API Gateway helps manage cross-cutting concerns like authentication, authorization, rate limiting, and logging, centralizing these tasks for easier management.</li></ul><h2>What we are going to build for the sample?</h2><p><img src=\"https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fgrpc-kubernetes-arch-project.png?alt=media&amp;token=0096deb5-89bb-4cb5-893f-e75a610e13dc\" alt=\"kubernetes+grpc architecture plan\" width=\"720px\">The project starts with the need to create a modern, scalable, and efficient architecture for handling multiple services. You aim to build a system where microservices can seamlessly communicate using gRPC for high-performance, low-latency interactions. The choice of gRPC over traditional HTTP APIs stems from its ability to use Protocol Buffers, enabling efficient serialization, lightweight message exchanges, and bi-directional streaming if needed. This makes it ideal for services like login authentication and movie information retrieval, which require quick and reliable data exchange.</p><p>In this project, you plan to create two gRPC services: one for handling user login (grpc-login-service) and another for managing movie-related data (grpc-movie-service). However, since most clients, like web browsers, communicate using HTTP 1.1 or HTTP/2, you introduce an API Gateway as the bridge. This gateway translates HTTP requests into gRPC calls, acting as the central entry point for all client communications. The gateway enables a smoother experience for clients while maintaining the performance benefits of gRPC in the backend.</p><p>To host and scale these services, you decide to deploy them on a Kubernetes cluster. Kubernetes provides a robust platform for container orchestration, ensuring that your services are resilient, scalable, and highly available. Your deployment plan includes pushing your service artifacts (Docker images) to the Google Cloud Artifact Registry and then using a 3-node Kubernetes cluster to deploy these services. Each gRPC service and the API Gateway are containerized and defined using Kubernetes YAML files for deployment and service management.</p><p>This architecture ensures a clean separation of concerns: each service focuses on its domain logic (e.g., login or movies), while the gateway abstracts communication complexities for the clients. It also leverages Kubernetes to provide automated scaling, load balancing, and fault tolerance, making the system ready for production-level traffic.</p><h2>Dive to API Gateway</h2><div><pre><code>const express = require('express');\nconst grpc = require('@grpc/grpc-js');\nconst protoLoader = require('@grpc/proto-loader');\nconst grpcWeb = require('grpc-web');\n\n// Load .proto files\nconst loginPackageDefinition = protoLoader.loadSync('login-service.proto', {\n&nbsp; &nbsp; keepCase: true,\n&nbsp; &nbsp; longs: String,\n&nbsp; &nbsp; enums: String,\n&nbsp; &nbsp; defaults: true,\n&nbsp; &nbsp; oneofs: true,\n});\n\nconst moviePackageDefinition = protoLoader.loadSync('movie-service.proto', {\n&nbsp; &nbsp; keepCase: true,\n&nbsp; &nbsp; longs: String,\n&nbsp; &nbsp; enums: String,\n&nbsp; &nbsp; defaults: true,\n&nbsp; &nbsp; oneofs: true,\n});\n\nconst loginServiceProto = grpc.loadPackageDefinition(loginPackageDefinition).LoginServiceProto;\nconst movieServiceProto = grpc.loadPackageDefinition(moviePackageDefinition).MovieServiceProto;\n\nconst app = express();\nconst port = 3000;\n\n// Set up your gRPC client\nconst login_client = new loginServiceProto('grpc-login-service:80', grpc.credentials.createInsecure());\nconst movie_client = new movieServiceProto('grpc-movie-service:80', grpc.credentials.createInsecure());\n\n// Middleware to parse JSON bodies\napp.use(express.json());\n\n// API endpoint to proxy to the gRPC service\napp.post('/api/login', (req, res) =&gt; {\n&nbsp; &nbsp; const { username, password } = req.body;\n\n&nbsp; &nbsp; // Call the gRPC method\n&nbsp; &nbsp; login_client.LoginMethod({ username, password }, (err, response) =&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; if (err) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; console.error('gRPC error:', err);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return res.status(500).send({ error: 'Internal Server Error' });\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; res.json(response);\n&nbsp; &nbsp; });\n});\n\napp.post('/api/movie', (req, res) =&gt; {\n&nbsp; &nbsp; const { title, description, rating } = req.body;\n&nbsp; &nbsp; // Call the gRPC method\n&nbsp; &nbsp; movie_client.MovieMethod({ title, description, rating }, (err, response) =&gt; {\n&nbsp; &nbsp; &nbsp; &nbsp; if (err) {\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; console.error('gRPC error:', err);\n&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; return res.status(500).send({ error: 'Internal Server Error' });\n&nbsp; &nbsp; &nbsp; &nbsp; }\n&nbsp; &nbsp; &nbsp; &nbsp; res.json(response);\n&nbsp; &nbsp; });\n});\n\n// Start the API Gateway server\napp.listen(port, () =&gt; {\n&nbsp; &nbsp; console.log(`API Gateway running at http://localhost:${port}`);\n});\n</code></pre></div><p>This code sets up a simple gRPC server for handling login requests. It begins by importing the necessary modules: @grpc/grpc-js, which provides the core gRPC functionalities, and @grpc/proto-loader, which is used to parse .proto files containing service definitions. The .proto file, login-service.proto, is loaded and configured using the protoLoader.loadSync method. This configuration ensures that field names are preserved, and specific Protocol Buffers types such as long integers, enumerations, default values, and oneof fields are appropriately handled. The loaded package definition is then passed to grpc.loadPackageDefinition to generate a usable gRPC object, which represents the LoginServiceProto service.</p><p>Next, the LoginMethod function is implemented to handle incoming login requests. This function receives the call object, which contains the client’s request data, and a callback function to send a response back to the client. It extracts the username and password from the request, constructs a success message, and sends a structured response containing the message and a status field via the callback. The response indicates that the login was processed successfully.</p><p>The gRPC server is then created using new grpc.Server(). The addService method registers the LoginServiceProto with the server and links it to the LoginMethod implementation. Finally, the server is started by binding it to the address 0.0.0.0 on port 50052 using the bindAsync method. For simplicity, the server uses insecure credentials, making it suitable for local testing but not for production. Once the server is running, a confirmation message is logged to indicate its readiness to handle incoming requests. Overall, this code provides a robust foundation for handling login operations as part of a microservices-based architecture. It enables fast and efficient communication between services through the gRPC protocol.</p><h2><strong>Dive to GRPC Service</strong></h2><div><pre><code>const grpc = require('@grpc/grpc-js');\nconst protoLoader = require('@grpc/proto-loader');\n\n\n// Load the .proto file\nconst packageDefinition = protoLoader.loadSync('movie-service.proto', {\n&nbsp; &nbsp; keepCase: true,\n&nbsp; &nbsp; longs: String,\n&nbsp; &nbsp; enums: String,\n&nbsp; &nbsp; defaults: true,\n&nbsp; &nbsp; oneofs: true,\n});\nconst MovieServiceProto = grpc.loadPackageDefinition(packageDefinition).MovieServiceProto;\n\n\n// Implement the ExampleMethod RPC\nfunction MovieMethod(call, callback) {\n&nbsp; &nbsp; const { title, description, rating } = call.request;\n&nbsp; &nbsp; const message = `Thank you for the feedback. The Movie Title is ${title} and the description is ${description} has a rating of ${rating}.`;\n&nbsp; &nbsp; const response = {\n&nbsp; &nbsp; &nbsp; &nbsp; message: message,\n&nbsp; &nbsp; &nbsp; &nbsp; status: 'success',\n&nbsp; &nbsp; }\n&nbsp; &nbsp; callback(null, response);\n}\n\n\n// Create the gRPC server\nconst server = new grpc.Server();\nserver.addService(MovieServiceProto.service, { MovieMethod: MovieMethod });\n\n\n// Start the server\nconst port = '0.0.0.0:50051';\nserver.bindAsync(port, grpc.ServerCredentials.createInsecure(), () =&gt; {\n&nbsp; &nbsp; console.log(`gRPC server running at ${port}`);\n});\n</code></pre></div><p>This code defines a gRPC server for handling requests related to movies. The server is built using the @grpc/grpc-js library for gRPC functionality and the @grpc/proto-loader library to load the .proto file that defines the movie service. Here's how it works in detail:</p><p>First, the .proto file (movie-service.proto) is loaded using protoLoader.loadSync. The protoLoader processes the Protocol Buffers definition into a format compatible with gRPC in Node.js. The options provided during the load process, such as keepCase, longs, and defaults, ensure that the original structure of the Protocol Buffers definition is preserved and mapped appropriately in JavaScript. The loaded package definition is then used to retrieve the MovieServiceProto object, which represents the service described in the .proto file.</p><p>Next, the MovieMethod function is implemented as the core logic for handling the gRPC request. This method represents an RPC (Remote Procedure Call) defined in the .proto file. When a client sends a request to this method, it provides details about a movie, such as title, description, and rating. The server responds by constructing a message that acknowledges the feedback and includes the provided details. A response object is created, which contains a message and a success status, and this is sent back to the client using the callback function.</p><p>The gRPC server is then created using new grpc.Server(). The addService method registers the MovieServiceProto.service with the server and maps it to the implementation (MovieMethod). This ensures that whenever a request for the MovieMethod RPC is received, the defined function is executed.</p><p>Finally, the server is started on port 50051 using the bindAsync method. The grpc.ServerCredentials.createInsecure() method specifies that the server will run without encryption, suitable for development environments. Once the server is bound to the specified port, it logs a confirmation message to the console, indicating that the gRPC server is running and ready to handle requests.</p><p>This setup is crucial for your project, as it provides the backend logic for handling movie-related data. It showcases how gRPC enables structured communication between services while maintaining high performance and clear data contracts defined in the .proto file.</p><p><strong>Note</strong>: There is another grpc service that implemented. and its excluding in this topic. You can create more similiar grpc service like above code.</p><h2><strong>Creating Dockerfile</strong></h2><p>To containerize your gRPC service and push it to Google Artifact Registry, you'll use a Dockerfile to define the container's build process and interact with the Artifact Registry to store your container image. Here's how you can approach this process:</p><p>The Dockerfile provides instructions for building the container image for your gRPC service. Below is an example Dockerfile for the movie-service:</p><div><pre><code># Use the official Node.js image as a base\nFROM node:16-alpine\n\n\n# Set the working directory in the container\nWORKDIR /usr/src/app\n\n\n# Copy the package.json and package-lock.json\nCOPY package*.json ./\n\n\n# Install dependencies\nRUN npm install\n\n\n# Copy the application code to the container\nCOPY . .\n\n\n# Expose the port the gRPC server will run on\nEXPOSE 50051\n\n\n# Start the gRPC service\nCMD [\"node\", \"index.js\"]\n</code></pre></div><p><strong>Explanation</strong>:</p><p>1. Base Image: We use the lightweight node:16-alpine image to reduce the container size while still providing all necessary Node.js dependencies.</p><p>2. Working Directory: The WORKDIR sets the container's working directory to /usr/src/app.</p><p>3. Copying Files: The COPY instructions add your package.json and the rest of your application files to the container.</p><p>4. Installing Dependencies: The RUN npm install command ensures that all required dependencies are installed.</p><p>5. Exposing Port: The EXPOSE 50051 makes the gRPC service accessible on port 50051.</p><p>6. Starting the Service: The CMD defines the command to run your gRPC service when the container starts.</p><p>7. Building the Docker Image</p><p>After creating the Dockerfile, you can build the Docker image for your gRPC service using the following command:</p><div><pre><code>docker build -t movie-service .\n</code></pre></div><p>This command tags the image as movie-service and uses the current directory (.) as the build context.</p><p><strong>Note</strong>: This Dockerfile only represent single project which refers to one of grpc service. You can create another Dockerfile for another service. which not really different with this one.</p><h2><strong>Tagging and Pushing to Artifact Registry</strong></h2><p>This approach allowed Kubernetes (GKE) to seamlessly retrieve and deploy the correct images for each service, ensuring a smooth and reliable deployment process.</p><p>To push the image to Google Artifact Registry, follow these steps:</p><p><strong>- Authenticate with Google Cloud</strong>: Run the following command to configure Docker to use Google Cloud credentials:</p><div><pre><code>gcloud auth configure-docker\n</code></pre></div><p><strong>- Tag the Image for Artifact Registry</strong>: Replace &lt;region&gt;, &lt;project-id&gt;, and &lt;repository-name&gt; with your Artifact Registry details. For example:</p><div><pre><code>docker tag movie-service &lt;region&gt;-docker.pkg.dev/&lt;project-id&gt;/&lt;repository-name&gt;/movie-service\n</code></pre></div><p><strong>- Push the Image</strong>: Push the tagged image to the Artifact Registry:</p><div><pre><code>docker push &lt;region&gt;-docker.pkg.dev/&lt;project-id&gt;/&lt;repository-name&gt;/movie-service\n</code></pre></div><h2><strong>Kubernetes Setup</strong></h2><p>To deploy your gRPC services to Kubernetes on Google Kubernetes Engine (GKE), you'll go through several steps, including creating the GKE cluster, setting up YAML files for deployments and services, and deploying the services. Here's a step-by-step explanation:</p><h3><strong>1. Creating a Kubernetes Cluster in GKE</strong></h3><p>First, you'll create a GKE cluster to host your services.</p><h4><strong>Step 1: Enable Required APIs</strong></h4><p>Ensure you have the GKE and Artifact Registry APIs enabled for your project:</p><div><pre><code>gcloud services enable container.googleapis.com artifactregistry.googleapis.com\n</code></pre></div><h4><strong>Step 2: Create the GKE Cluster</strong></h4><p>Run the following command to create a Kubernetes cluster:</p><div><pre><code>gcloud container clusters create grpc-cluster \\\n    --num-nodes=3 \\\n    --region=us-central1 \\\n    --enable-ip-alias\n</code></pre></div><p>--num-nodes=3: Creates a cluster with 3 nodes.</p><p>--region=us-central1: Specifies the cluster region. Adjust this based on your location.</p><p>--enable-ip-alias: Enables VPC-native networking.</p><h4><strong>Step 3: Connect to the Cluster</strong></h4><p>To interact with your GKE cluster, fetch its credentials:</p><div><pre><code>gcloud container clusters get-credentials grpc-cluster --region=us-central1\n</code></pre></div><p>Now, your local kubectl command is connected to your GKE cluster.</p><h3><strong>2. Preparing Kubernetes YAML Files</strong></h3><p>You need two types of YAML files for each service: a Deployment file and a Service file.</p><p>Example: Deployment YAML (movie-service-deployment.yaml)</p><p>This file defines how your gRPC service is deployed.</p><div><pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: movie-service\n  labels:\n    app: movie-service\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: movie-service\n  template:\n    metadata:\n      labels:\n        app: movie-service\n    spec:\n      containers:\n      - name: movie-service\n        image: us-central1-docker.pkg.dev/&lt;project-id&gt;/&lt;repository-name&gt;/movie-service:latest\n        ports:\n        - containerPort: 50051\n</code></pre></div><p>Explanation:</p><p>- replicas: Specifies the number of pod instances for the service.</p><p>- image: Points to the Docker image in Google Artifact Registry.</p><p>- ports: Exposes port 50051, which the gRPC service listens to.</p><p>Example: Service YAML (movie-service-service.yaml)</p><p>This file exposes your gRPC service within the cluster or to the internet.</p><div><pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: movie-service\nspec:\n  selector:\n    app: movie-service\n  ports:\n  - protocol: TCP\n    port: 50051\n    targetPort: 50051\n  type: ClusterIP\n</code></pre></div><h4>Explanation:</h4><p><strong>type</strong>: ClusterIP: Exposes the service within the Kubernetes cluster. Use LoadBalancer if you need external access.</p><p><strong>targetPort</strong>: Maps the service port to the container port.</p><h3><strong>3. Deploying the Services</strong></h3><p>After creating the YAML files, apply them to your cluster.</p><h4><strong>Step 1: Deploy the Movie Service</strong></h4><p>Run the following commands:</p><div><pre><code>kubectl apply -f movie-service-deployment.yaml\nkubectl apply -f movie-service-service.yaml\n</code></pre></div><h4><strong>Step 2: Verify the Deployment</strong></h4><p>Check the pods and services to ensure they are running:</p><div><pre><code>kubectl get pods\nkubectl get svc\n</code></pre></div><h3><strong>4. Deploying Additional Services</strong></h3><p>Follow the same process for your login service:</p><p>1. Create login-service-deployment.yaml and login-service-service.yaml.</p><p>2. Apply the YAML files using kubectl apply.</p><h2><strong>Conlusion</strong></h2><p>Building a modern, scalable system is more than just deploying code—it's a journey into the intricacies of microservices, networking, containerization, and orchestration. From the outset, we delved into the necessity of gRPC, unlocking fast, efficient communication between services. By creating two gRPC services. we saw how to design robust servers capable of processing structured requests and returning meaningful responses. Translating these gRPC methods into HTTP/1.1 via an API Gateway expanded their accessibility, making them usable by any client.</p><p>Docker came into play as the backbone of portability and consistency, enabling us to containerize and push our services to Google Artifact Registry. With Kubernetes, we embraced the power of orchestration, deploying services on a GKE cluster, ensuring high availability, load balancing, and seamless scaling. YAML files gave us control over deployments, allowing precise management of replicas, ports, and service types. The API Gateway tied everything together, creating a single point of entry for clients while efficiently routing traffic to the respective gRPC services.</p><p>This project showcases not just technical implementations but also the thought process behind building scalable, maintainable systems. Each step—from writing the first line of code to testing the final deployment—demonstrates the power of modern tools and practices. It's a reminder of how containerization, orchestration, and thoughtful design transform complex challenges into elegant solutions.</p><p>The journey doesn’t stop here. With this foundation, the possibilities are limitless—whether adding more services, optimizing deployments, or exploring advanced Kubernetes features like autoscaling and monitoring. This project serves as a testament to the potential of modern cloud-native development and a stepping stone for future innovation.</p><p>So here’s to embracing complexity, simplifying solutions, and building systems that not only work but inspire. The world of scalable systems awaits—where will you take it next?</p>",
    "image": "https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2Fgrpc%20with%20kubernetes.png?alt=media&token=ae61e7f8-2088-416f-924c-512461e18206",
    "image_alt": "Kubernetes+GRPC Background",
    "slug": "Building-a-Robust-Microservices-Architecture-From-gRPC-to-Kubernetes"
  },
  {
    "blog_id": "3b169c47-8359-4743-9dd2-eebbb68e0c52",
    "title": "Building a Video Streaming Platform with AWS S3, HLS, and Node.js",
    "short_description": "Ever wondered how your favorite streaming platforms deliver smooth, high-quality videos? Streaming video content is a cornerstone of modern web applications. Let’s explore how to build a video streaming service step by step.",
    "timestamp": "2024-12-15 10:42:44",
    "description": "<p>By the end of this guide, you'll have the skills to:</p><p>- Store video chunks securely in AWS S3.</p><p>- Stream videos dynamically to users using HLS.</p><p>- Enable users to upload videos, automatically process them into HLS chunks, and store them in S3.</p><p><strong>Ready to get started? Let's dive in!</strong></p><h1><strong>Step 1: Storing Video Chunks in AWS S3</strong></h1><p>To stream videos, we first need to upload .ts (MPEG transport stream) files and a .m3u8 playlist to an AWS S3 bucket. Follow these steps to upload your files:</p><h3>Why AWS S3?</h3><p>AWS S3 provides a scalable, reliable, and secure storage solution, making it perfect for handling large video files. Using the AWS CLI simplifies the upload process and integrates easily into automation pipelines.</p><h3>Step-by-Step Instructions:</h3><p>1. Open your terminal.</p><p>2. Run the following commands to upload the video chunks and playlist:</p><div><pre><code>aws s3 cp output0.ts s3://your-bucket-name/path-to-folder/\naws s3 cp playlist.m3u8 s3://your-bucket-name/path-to-folder/\n</code></pre></div><p>While we’re using the AWS CLI here, you could also use the AWS Management Console or SDKs (e.g., AWS SDK for JavaScript) if you prefer a graphical interface or code-based interaction.</p><p>Once uploaded, your files will be securely stored and accessible for streaming. Let’s move to setting up the backend!</p><h1><strong>Step 2: Streaming the Video with Express.js</strong></h1><p>Now that our video chunks are in S3, we need a backend to fetch and serve them to the client. We’ll use Node.js with Express.js to handle this.</p><h3>Backend Setup:</h3><p>1. Create a new Node.js project and install the necessary packages:</p><div><pre><code>npm init -y\nnpm install express @aws-sdk/client-s3\n</code></pre></div><p>2. Add the following code to your server.js file: </p><div><pre><code>import express from 'express';\nimport { S3Client, GetObjectCommand } from '@aws-sdk/client-s3';\nimport stream from 'stream';\n\nconst app = express();\nconst s3 = new S3Client({ region: 'your-region' });\n\n// Endpoint to serve the HLS playlist\napp.get('/play/playlist.m3u8', async (req, res) =&gt; {\n&nbsp;&nbsp;try {\n&nbsp;&nbsp;&nbsp;&nbsp;const command = new GetObjectCommand({\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bucket: 'your-bucket-name',\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Key: 'path-to-folder/playlist.m3u8',\n&nbsp;&nbsp;&nbsp;&nbsp;});\n&nbsp;&nbsp;&nbsp;&nbsp;const s3Response = await s3.send(command);\n&nbsp;&nbsp;&nbsp;&nbsp;s3Response.Body.pipe(res);\n&nbsp;&nbsp;} catch (err) {\n&nbsp;&nbsp;&nbsp;&nbsp;console.error('Error fetching playlist:', err);\n&nbsp;&nbsp;&nbsp;&nbsp;res.status(500).send('Error fetching playlist');\n&nbsp;&nbsp;}\n});\n\n// Endpoint to serve video chunks\napp.get('/play/video/:segment', async (req, res) =&gt; {\n&nbsp;&nbsp;try {\n&nbsp;&nbsp;&nbsp;&nbsp;const command = new GetObjectCommand({\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bucket: 'your-bucket-name',\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Key: `path-to-folder/${req.params.segment}`,\n&nbsp;&nbsp;&nbsp;&nbsp;});\n&nbsp;&nbsp;&nbsp;&nbsp;const s3Response = await s3.send(command);\n&nbsp;&nbsp;&nbsp;&nbsp;s3Response.Body.pipe(res);\n&nbsp;&nbsp;} catch (err) {\n&nbsp;&nbsp;&nbsp;&nbsp;console.error('Error fetching video segment:', err);\n&nbsp;&nbsp;&nbsp;&nbsp;res.status(500).send('Error fetching video segment');\n&nbsp;&nbsp;}\n});\n\nconst PORT = 3000;\napp.listen(PORT, () =&gt; {\n&nbsp;&nbsp;console.log(`Server is running on http://localhost:${PORT}`);\n});\n</code></pre></div><h3>What’s Happening Here?</h3><p><strong>- Playlist Endpoint</strong>: Fetches and streams the .m3u8 file from S3.</p><p><strong>- Video Chunks Endpoint</strong>: Dynamically fetches .ts chunks based on the client’s request.</p><p>Once the backend is running, we can serve video content to the client. Let’s bring it all together on the frontend.</p><h1><strong>Step 3: Playing the Video on the Client-Side</strong></h1><p>To play the HLS video stream in the browser, we’ll use the <code>&lt;video&gt;</code> HTML tag and the HLS.js library for compatibility with all modern browsers.</p><h3>Implementation:</h3><p>1. Create an index.html file with the following content:</p><div><pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n&nbsp;&lt;meta charset=\"UTF-8\"&gt;\n&nbsp;&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n&nbsp;&lt;title&gt;Video Streaming&lt;/title&gt;\n&nbsp;&lt;script src=\"https://cdn.jsdelivr.net/npm/hls.js@latest\"&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&nbsp;&lt;h1&gt;Video Streaming Example&lt;/h1&gt;\n&nbsp;&lt;video id=\"videoPlayer\" controls width=\"720\" autoplay&gt;&lt;/video&gt;\n\n&nbsp;&lt;script&gt;\n&nbsp;&nbsp;const video = document.getElementById('videoPlayer');\n&nbsp;&nbsp;const videoSrc = 'http://localhost:3000/play/playlist.m3u8';\n\n&nbsp;&nbsp;if (Hls.isSupported()) {\n&nbsp;&nbsp;&nbsp;const hls = new Hls();\n&nbsp;&nbsp;&nbsp;hls.loadSource(videoSrc);\n&nbsp;&nbsp;&nbsp;hls.attachMedia(video);\n&nbsp;&nbsp;} else if (video.canPlayType('application/vnd.apple.mpegurl')) {\n&nbsp;&nbsp;&nbsp;video.src = videoSrc;\n&nbsp;&nbsp;} else {\n&nbsp;&nbsp;&nbsp;console.error('This browser does not support HLS streaming');\n&nbsp;&nbsp;}\n&nbsp;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre></div><h3>Key Points:</h3><p>- The browser fetches the <code>.m3u8</code> playlist, which directs it to download the <code>.ts</code> chunks for smooth playback.</p><p>- The HLS.js library ensures compatibility with browsers that don’t natively support HLS.</p><p>Now you have a working video player! Let’s take it a step further by allowing users to upload videos.</p><h1><strong>Step 4: Allowing Users to Upload Videos</strong></h1><p>What if users want to upload their own videos? We can process those videos into HLS chunks and store them in S3.</p><h3>Backend for Uploading and Processing:</h3><p>1. Install the required packages:</p><div><pre><code>npm install multer fluent-ffmpeg\n</code></pre></div><p>2. Update your server.js file with the following:</p><div><pre><code>import multer from 'multer';\nimport ffmpeg from 'fluent-ffmpeg';\nimport { PutObjectCommand } from '@aws-sdk/client-s3';\nimport fs from 'fs';\n\nconst upload = multer({ dest: 'uploads/' });\n\napp.post('/upload', upload.single('video'), (req, res) =&gt; {\n&nbsp;&nbsp;const inputPath = req.file.path;\n&nbsp;&nbsp;const outputPath = 'processed/';\n\n&nbsp;&nbsp;ffmpeg(inputPath)\n&nbsp;&nbsp;&nbsp;&nbsp;.output(`${outputPath}playlist.m3u8`)\n&nbsp;&nbsp;&nbsp;&nbsp;.outputOptions([\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'-hls_time 10',\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'-hls_list_size 0',\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'-f hls',\n&nbsp;&nbsp;&nbsp;&nbsp;])\n&nbsp;&nbsp;&nbsp;&nbsp;.on('end', async () =&gt; {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;// Upload .m3u8 and .ts files to S3\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;const filesToUpload = fs.readdirSync(outputPath);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for (const file of filesToUpload) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;const command = new PutObjectCommand({\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Bucket: 'your-bucket-name',\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Key: `path-to-folder/${file}`,\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Body: fs.createReadStream(`${outputPath}${file}`),\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;});\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;await s3.send(command);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.send('Video uploaded and processed successfully!');\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} catch (err) {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.error('Error uploading to S3:', err);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.status(500).send('Error uploading video.');\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n&nbsp;&nbsp;&nbsp;&nbsp;})\n&nbsp;&nbsp;&nbsp;&nbsp;.on('error', (err) =&gt; {\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;console.error('Error processing video:', err);\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;res.status(500).send('Error processing video.');\n&nbsp;&nbsp;&nbsp;&nbsp;})\n&nbsp;&nbsp;&nbsp;&nbsp;.run();\n});\n</code></pre></div><h3>Workflow:</h3><p>1. Users upload a video via the /upload endpoint.</p><p>2. FFmpeg processes the video into HLS chunks.</p><p>3. The processed files are automatically uploaded to S3.</p><h1><strong>Final Thoughts</strong></h1><p>Congratulations! You’ve built a fully functional video streaming platform. Here's a recap of what we accomplished:</p><p><strong>- Secure Storage</strong>: Used AWS S3 for reliable and scalable storage.</p><p><strong>- Seamless Streaming</strong>: Enabled dynamic streaming with HLS.</p><p><strong>- User Uploads</strong>: Automated video processing and storage with FFmpeg and Node.js.</p><p>This architecture is scalable and can serve as the foundation</p>",
    "image": "https://firebasestorage.googleapis.com/v0/b/personal-blog-darmajr.appspot.com/o/blog-content%2FHLS-IMAGE.jpg?alt=media&token=8077c433-3d64-4627-86d5-e9605a6aa9a2",
    "image_alt": "HLS background",
    "slug": "Building-a-Video-Streaming-Platform-with-AWS-S3-HLS-and-Nodejs"
  }
]